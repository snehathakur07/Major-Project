{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset = \n",
      "['Grupo_0', 'Grupo_1', 'Grupo_2', 'Grupo_3', 'Grupo_4', 'Grupo_5']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define dataset path and image size\n",
    "dataset_path = \"data\"  # Path to your dataset\n",
    "image_size = (120, 160)  # Resize to 120x160 for Small-VGG\n",
    "\n",
    "print('Our dataset = ')\n",
    "print(os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LG images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following 0 files are corrupt or encountered error: \n",
      " []\n",
      "Read 2820 images from the LG folder with shape (2820, 160, 120)\n"
     ]
    }
   ],
   "source": [
    "# Function to load images from the LG folder (following the exact structure)\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    names = []\n",
    "    corruptedFiles = []\n",
    "    image_extensions = [\"bmp\"]\n",
    "\n",
    "    # Traverse through the group -> subject -> LG -> session -> anotherfolder -> images\n",
    "    for group_folder in os.listdir(folder_path):\n",
    "        group_path = os.path.join(folder_path, group_folder)\n",
    "        if os.path.isdir(group_path):  # If it is a group folder\n",
    "            for subject_folder in os.listdir(group_path):\n",
    "                subject_path = os.path.join(group_path, subject_folder)\n",
    "                if os.path.isdir(subject_path):  # If it is a subject folder\n",
    "                    lg_folder = os.path.join(subject_path, \"LG\")  # Looking specifically for the 'LG' folder\n",
    "                    if os.path.isdir(lg_folder):  # Only process if 'LG' folder exists\n",
    "                        # Iterate over sessions inside 'LG' folder\n",
    "                        for session_folder in os.listdir(lg_folder):\n",
    "                            session_path = os.path.join(lg_folder, session_folder)\n",
    "                            if os.path.isdir(session_path):  # Check each session\n",
    "                                # Iterate over each subfolder inside the session\n",
    "                                for subfolder in os.listdir(session_path):\n",
    "                                    subfolder_path = os.path.join(session_path, subfolder)\n",
    "                                    if os.path.isdir(subfolder_path):  # If it's a subfolder containing images\n",
    "                                        # Now we go through all the image files\n",
    "                                        for file in os.listdir(subfolder_path):\n",
    "                                            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                                                img_path = os.path.join(subfolder_path, file)\n",
    "                                                try:\n",
    "                                                    # Read image in grayscale and resize\n",
    "                                                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                                                    if img is not None:\n",
    "                                                        img = cv2.resize(img, image_size)\n",
    "                                                        images.append(img)\n",
    "                                                        labels.append(file[6] != '0')  # Assuming the label is based on the file name (0 or 1)\n",
    "                                                        names.append(file)\n",
    "                                                except Exception as e:\n",
    "                                                    corruptedFiles.append((img_path, str(e)))\n",
    "\n",
    "    print(f\"Following {len(corruptedFiles)} files are corrupt or encountered error: \\n {corruptedFiles}\")\n",
    "    \n",
    "    # Return the images, labels, and names if any images were found\n",
    "    if images:\n",
    "        return np.array(images), np.array(labels), np.array(names)\n",
    "    else:\n",
    "        print(\"No images were loaded.\")\n",
    "        return np.array([]), np.array([]), np.array([])  # Return empty arrays if no images are found\n",
    "\n",
    "# Load dataset (only from the LG folder)\n",
    "images, labels, names = load_images_from_folder(dataset_path)\n",
    "print(f\"Read {len(images)} images from the LG folder with shape {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "images = images / 255.0  # Normalize pixel values\n",
    "images = images.reshape(images.shape[0], image_size[0], image_size[1], 1)  # Add channel dimension\n",
    "labels = to_categorical(labels, num_classes=2)  # Convert labels to one-hot encoding\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.4, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Small-VGG model\n",
    "def create_small_vgg():\n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_size[0], image_size[1], 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Block 2\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Block 3\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sneha Thakur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 661ms/step - accuracy: 0.8116 - loss: 0.6976 - val_accuracy: 0.7965 - val_loss: 0.5066\n",
      "Epoch 2/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 633ms/step - accuracy: 0.8111 - loss: 0.4922 - val_accuracy: 0.7965 - val_loss: 0.5268\n",
      "Epoch 3/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 627ms/step - accuracy: 0.7975 - loss: 0.5130 - val_accuracy: 0.7965 - val_loss: 0.5079\n",
      "Epoch 4/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 659ms/step - accuracy: 0.7937 - loss: 0.5151 - val_accuracy: 0.7965 - val_loss: 0.5061\n",
      "Epoch 5/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 626ms/step - accuracy: 0.8198 - loss: 0.4772 - val_accuracy: 0.7965 - val_loss: 0.5066\n",
      "Epoch 6/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 632ms/step - accuracy: 0.7967 - loss: 0.5051 - val_accuracy: 0.7965 - val_loss: 0.5049\n",
      "Epoch 7/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.8076 - loss: 0.4908 - val_accuracy: 0.7965 - val_loss: 0.5057\n",
      "Epoch 8/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 625ms/step - accuracy: 0.7999 - loss: 0.5045 - val_accuracy: 0.7965 - val_loss: 0.5040\n",
      "Epoch 9/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 0.8056 - loss: 0.4944 - val_accuracy: 0.7965 - val_loss: 0.5036\n",
      "Epoch 10/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 0.8135 - loss: 0.4776 - val_accuracy: 0.7965 - val_loss: 0.5084\n",
      "Epoch 11/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 0.7842 - loss: 0.5215 - val_accuracy: 0.7965 - val_loss: 0.5058\n",
      "Epoch 12/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 629ms/step - accuracy: 0.8125 - loss: 0.4821 - val_accuracy: 0.7965 - val_loss: 0.5057\n",
      "Epoch 13/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 614ms/step - accuracy: 0.7961 - loss: 0.5072 - val_accuracy: 0.7965 - val_loss: 0.5086\n",
      "Epoch 14/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 612ms/step - accuracy: 0.8033 - loss: 0.4914 - val_accuracy: 0.7965 - val_loss: 0.5071\n",
      "Epoch 15/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 614ms/step - accuracy: 0.8091 - loss: 0.4767 - val_accuracy: 0.7965 - val_loss: 0.5083\n",
      "Epoch 16/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 615ms/step - accuracy: 0.7988 - loss: 0.4937 - val_accuracy: 0.7817 - val_loss: 0.5293\n",
      "Epoch 17/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 616ms/step - accuracy: 0.8111 - loss: 0.4683 - val_accuracy: 0.7965 - val_loss: 0.5144\n",
      "Epoch 18/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 616ms/step - accuracy: 0.7838 - loss: 0.4973 - val_accuracy: 0.7935 - val_loss: 0.5246\n",
      "Epoch 19/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 608ms/step - accuracy: 0.7955 - loss: 0.4807 - val_accuracy: 0.7965 - val_loss: 0.5087\n",
      "Epoch 20/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 607ms/step - accuracy: 0.8036 - loss: 0.4833 - val_accuracy: 0.7729 - val_loss: 0.5262\n",
      "Epoch 21/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 608ms/step - accuracy: 0.8063 - loss: 0.4402 - val_accuracy: 0.7906 - val_loss: 0.5261\n",
      "Epoch 22/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 609ms/step - accuracy: 0.8059 - loss: 0.4525 - val_accuracy: 0.7876 - val_loss: 0.5145\n",
      "Epoch 23/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 607ms/step - accuracy: 0.8260 - loss: 0.4174 - val_accuracy: 0.7906 - val_loss: 0.5358\n",
      "Epoch 24/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 607ms/step - accuracy: 0.8339 - loss: 0.3768 - val_accuracy: 0.7640 - val_loss: 0.5694\n",
      "Epoch 25/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 607ms/step - accuracy: 0.8318 - loss: 0.3766 - val_accuracy: 0.7935 - val_loss: 0.5766\n",
      "Epoch 26/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 606ms/step - accuracy: 0.8403 - loss: 0.3501 - val_accuracy: 0.7876 - val_loss: 0.5649\n",
      "Epoch 27/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 609ms/step - accuracy: 0.8714 - loss: 0.2940 - val_accuracy: 0.8083 - val_loss: 0.6162\n",
      "Epoch 28/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 607ms/step - accuracy: 0.8915 - loss: 0.2556 - val_accuracy: 0.7906 - val_loss: 0.6192\n",
      "Epoch 29/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 607ms/step - accuracy: 0.9066 - loss: 0.2421 - val_accuracy: 0.8201 - val_loss: 0.5980\n",
      "Epoch 30/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 748ms/step - accuracy: 0.9190 - loss: 0.1856 - val_accuracy: 0.7935 - val_loss: 0.5752\n",
      "Epoch 31/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9561 - loss: 0.1280 - val_accuracy: 0.7876 - val_loss: 0.7764\n",
      "Epoch 32/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 631ms/step - accuracy: 0.9673 - loss: 0.1132 - val_accuracy: 0.7994 - val_loss: 0.8728\n",
      "Epoch 33/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 618ms/step - accuracy: 0.9676 - loss: 0.0818 - val_accuracy: 0.8171 - val_loss: 1.0162\n",
      "Epoch 34/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 0.9580 - loss: 0.1081 - val_accuracy: 0.8053 - val_loss: 0.7473\n",
      "Epoch 35/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 617ms/step - accuracy: 0.9886 - loss: 0.0493 - val_accuracy: 0.8201 - val_loss: 0.8194\n",
      "Epoch 36/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 0.9908 - loss: 0.0380 - val_accuracy: 0.8348 - val_loss: 1.0463\n",
      "Epoch 37/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 626ms/step - accuracy: 0.9894 - loss: 0.0303 - val_accuracy: 0.8466 - val_loss: 0.8718\n",
      "Epoch 38/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 0.9895 - loss: 0.0332 - val_accuracy: 0.8171 - val_loss: 0.9362\n",
      "Epoch 39/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 619ms/step - accuracy: 0.9940 - loss: 0.0251 - val_accuracy: 0.8260 - val_loss: 0.9072\n",
      "Epoch 40/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 619ms/step - accuracy: 0.9930 - loss: 0.0292 - val_accuracy: 0.8319 - val_loss: 0.9667\n",
      "Epoch 41/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 619ms/step - accuracy: 0.9975 - loss: 0.0149 - val_accuracy: 0.8053 - val_loss: 1.1156\n",
      "Epoch 42/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 0.9754 - loss: 0.0625 - val_accuracy: 0.8171 - val_loss: 0.9608\n",
      "Epoch 43/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 619ms/step - accuracy: 0.9923 - loss: 0.0194 - val_accuracy: 0.8083 - val_loss: 1.1258\n",
      "Epoch 44/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9938 - loss: 0.0152 - val_accuracy: 0.8201 - val_loss: 1.2170\n",
      "Epoch 45/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 618ms/step - accuracy: 0.9924 - loss: 0.0235 - val_accuracy: 0.8407 - val_loss: 1.1896\n",
      "Epoch 46/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 618ms/step - accuracy: 0.9998 - loss: 0.0061 - val_accuracy: 0.8319 - val_loss: 1.2279\n",
      "Epoch 47/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9987 - loss: 0.0055 - val_accuracy: 0.8260 - val_loss: 1.1311\n",
      "Epoch 48/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 0.0030 - val_accuracy: 0.8319 - val_loss: 1.4102\n",
      "Epoch 49/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 619ms/step - accuracy: 0.9954 - loss: 0.0196 - val_accuracy: 0.8083 - val_loss: 1.2795\n",
      "Epoch 50/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9980 - loss: 0.0089 - val_accuracy: 0.8407 - val_loss: 1.2149\n",
      "Epoch 51/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 0.9978 - loss: 0.0063 - val_accuracy: 0.8348 - val_loss: 1.2604\n",
      "Epoch 52/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 619ms/step - accuracy: 0.9906 - loss: 0.0250 - val_accuracy: 0.7817 - val_loss: 1.2145\n",
      "Epoch 53/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 0.9872 - loss: 0.0382 - val_accuracy: 0.8142 - val_loss: 1.1828\n",
      "Epoch 54/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 0.9940 - loss: 0.0095 - val_accuracy: 0.8260 - val_loss: 1.1489\n",
      "Epoch 55/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.8319 - val_loss: 1.3442\n",
      "Epoch 56/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 628ms/step - accuracy: 0.9999 - loss: 0.0014 - val_accuracy: 0.8112 - val_loss: 1.1531\n",
      "Epoch 57/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.8230 - val_loss: 1.2542\n",
      "Epoch 58/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8319 - val_loss: 1.4562\n",
      "Epoch 59/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.8407 - val_loss: 1.5209\n",
      "Epoch 60/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.8230 - val_loss: 1.4473\n",
      "Epoch 61/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 5.0357e-04 - val_accuracy: 0.8289 - val_loss: 1.5026\n",
      "Epoch 62/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 3.5225e-04 - val_accuracy: 0.8201 - val_loss: 1.4175\n",
      "Epoch 63/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 4.2328e-04 - val_accuracy: 0.8319 - val_loss: 1.5032\n",
      "Epoch 64/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 1.7583e-04 - val_accuracy: 0.8289 - val_loss: 1.5057\n",
      "Epoch 65/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 1.7345e-04 - val_accuracy: 0.8319 - val_loss: 1.5344\n",
      "Epoch 66/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.5450e-04 - val_accuracy: 0.8319 - val_loss: 1.5378\n",
      "Epoch 67/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 1.9577e-04 - val_accuracy: 0.8230 - val_loss: 1.5114\n",
      "Epoch 68/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 1.1498e-04 - val_accuracy: 0.8171 - val_loss: 1.5378\n",
      "Epoch 69/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 5.7870e-05 - val_accuracy: 0.8319 - val_loss: 1.5639\n",
      "Epoch 70/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 1.2377e-04 - val_accuracy: 0.8142 - val_loss: 1.5442\n",
      "Epoch 71/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9930 - loss: 0.0281 - val_accuracy: 0.7670 - val_loss: 1.0223\n",
      "Epoch 72/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 0.9645 - loss: 0.1048 - val_accuracy: 0.8053 - val_loss: 1.1868\n",
      "Epoch 73/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 0.9912 - loss: 0.0272 - val_accuracy: 0.8083 - val_loss: 1.3904\n",
      "Epoch 74/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9945 - loss: 0.0143 - val_accuracy: 0.8024 - val_loss: 1.3885\n",
      "Epoch 75/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 0.0013 - val_accuracy: 0.8230 - val_loss: 1.3966\n",
      "Epoch 76/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.8289 - val_loss: 1.3791\n",
      "Epoch 77/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 627ms/step - accuracy: 1.0000 - loss: 7.4542e-04 - val_accuracy: 0.8260 - val_loss: 1.3415\n",
      "Epoch 78/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 5.5590e-04 - val_accuracy: 0.8289 - val_loss: 1.5542\n",
      "Epoch 79/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 3.3271e-04 - val_accuracy: 0.8319 - val_loss: 1.6791\n",
      "Epoch 80/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9942 - loss: 0.0175 - val_accuracy: 0.8112 - val_loss: 1.6260\n",
      "Epoch 81/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 0.9862 - loss: 0.0383 - val_accuracy: 0.8230 - val_loss: 1.2203\n",
      "Epoch 82/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 0.9935 - loss: 0.0142 - val_accuracy: 0.8348 - val_loss: 1.5934\n",
      "Epoch 83/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 620ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.8201 - val_loss: 1.4716\n",
      "Epoch 84/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 5.9360e-04 - val_accuracy: 0.8142 - val_loss: 1.6593\n",
      "Epoch 85/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 625ms/step - accuracy: 0.9970 - loss: 0.0047 - val_accuracy: 0.8053 - val_loss: 1.5388\n",
      "Epoch 86/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.8142 - val_loss: 1.6506\n",
      "Epoch 87/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 1.7916e-04 - val_accuracy: 0.8112 - val_loss: 1.6639\n",
      "Epoch 88/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 6.6925e-04 - val_accuracy: 0.8112 - val_loss: 1.7496\n",
      "Epoch 89/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 4.3748e-04 - val_accuracy: 0.8083 - val_loss: 1.7254\n",
      "Epoch 90/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 1.8416e-04 - val_accuracy: 0.8230 - val_loss: 1.7055\n",
      "Epoch 91/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 7.2028e-05 - val_accuracy: 0.8230 - val_loss: 1.7373\n",
      "Epoch 92/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 1.2334e-04 - val_accuracy: 0.8201 - val_loss: 1.6955\n",
      "Epoch 93/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 4.9441e-05 - val_accuracy: 0.8171 - val_loss: 1.7290\n",
      "Epoch 94/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 624ms/step - accuracy: 1.0000 - loss: 2.0867e-04 - val_accuracy: 0.8230 - val_loss: 1.6027\n",
      "Epoch 95/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 626ms/step - accuracy: 1.0000 - loss: 1.5612e-04 - val_accuracy: 0.8201 - val_loss: 1.7252\n",
      "Epoch 96/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 622ms/step - accuracy: 1.0000 - loss: 8.9922e-05 - val_accuracy: 0.8201 - val_loss: 1.7376\n",
      "Epoch 97/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 3.0609e-05 - val_accuracy: 0.8201 - val_loss: 1.7471\n",
      "Epoch 98/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 3.8349e-05 - val_accuracy: 0.8201 - val_loss: 1.7604\n",
      "Epoch 99/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 623ms/step - accuracy: 1.0000 - loss: 2.8215e-05 - val_accuracy: 0.8171 - val_loss: 1.7900\n",
      "Epoch 100/100\n",
      "\u001b[1m85/85\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 621ms/step - accuracy: 1.0000 - loss: 7.1591e-05 - val_accuracy: 0.8171 - val_loss: 1.7746\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8542 - loss: 1.3131\n",
      "Test Accuracy: 84.57%\n"
     ]
    }
   ],
   "source": [
    "# Compile and train the Small-VGG model\n",
    "model = create_small_vgg()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=16, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.46      0.57       247\n",
      "           1       0.86      0.95      0.91       881\n",
      "\n",
      "    accuracy                           0.85      1128\n",
      "   macro avg       0.80      0.71      0.74      1128\n",
      "weighted avg       0.84      0.85      0.83      1128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
