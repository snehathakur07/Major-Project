{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our dataset = \n",
      "['Grupo_0', 'Grupo_1', 'Grupo_2', 'Grupo_3', 'Grupo_4', 'Grupo_5']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define dataset path and image size\n",
    "dataset_path = \"data\"  # Path to your dataset\n",
    "image_size = (120, 160)  # Resize to 120x160 for Small-VGG\n",
    "\n",
    "print('Our dataset = ')\n",
    "print(os.listdir(dataset_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following 0 files are corrupt or encountered error: \n",
      " []\n",
      "Read 2820 images from the LG folder with shape (2820, 160, 120)\n"
     ]
    }
   ],
   "source": [
    "# Function to load images from the LG folder (following the exact structure)\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    names = []\n",
    "    corruptedFiles = []\n",
    "    image_extensions = [\"bmp\"]\n",
    "\n",
    "    # Traverse through the group -> subject -> LG -> session -> anotherfolder -> images\n",
    "    for group_folder in os.listdir(folder_path):\n",
    "        group_path = os.path.join(folder_path, group_folder)\n",
    "        if os.path.isdir(group_path):  # If it is a group folder\n",
    "            for subject_folder in os.listdir(group_path):\n",
    "                subject_path = os.path.join(group_path, subject_folder)\n",
    "                if os.path.isdir(subject_path):  # If it is a subject folder\n",
    "                    lg_folder = os.path.join(subject_path, \"LG\")  # Looking specifically for the 'LG' folder\n",
    "                    if os.path.isdir(lg_folder):  # Only process if 'LG' folder exists\n",
    "                        # Iterate over sessions inside 'LG' folder\n",
    "                        for session_folder in os.listdir(lg_folder):\n",
    "                            session_path = os.path.join(lg_folder, session_folder)\n",
    "                            if os.path.isdir(session_path):  # Check each session\n",
    "                                # Iterate over each subfolder inside the session\n",
    "                                for subfolder in os.listdir(session_path):\n",
    "                                    subfolder_path = os.path.join(session_path, subfolder)\n",
    "                                    if os.path.isdir(subfolder_path):  # If it's a subfolder containing images\n",
    "                                        # Now we go through all the image files\n",
    "                                        for file in os.listdir(subfolder_path):\n",
    "                                            if any(file.lower().endswith(ext) for ext in image_extensions):\n",
    "                                                img_path = os.path.join(subfolder_path, file)\n",
    "                                                try:\n",
    "                                                    # Read image in grayscale and resize\n",
    "                                                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                                                    if img is not None:\n",
    "                                                        img = cv2.resize(img, image_size)\n",
    "                                                        images.append(img)\n",
    "                                                        labels.append(file[6] != '0')  # Assuming the label is based on the file name (0 or 1)\n",
    "                                                        names.append(file)\n",
    "                                                except Exception as e:\n",
    "                                                    corruptedFiles.append((img_path, str(e)))\n",
    "\n",
    "    print(f\"Following {len(corruptedFiles)} files are corrupt or encountered error: \\n {corruptedFiles}\")\n",
    "    \n",
    "    # Return the images, labels, and names if any images were found\n",
    "    if images:\n",
    "        return np.array(images), np.array(labels), np.array(names)\n",
    "    else:\n",
    "        print(\"No images were loaded.\")\n",
    "        return np.array([]), np.array([]), np.array([])  # Return empty arrays if no images are found\n",
    "\n",
    "# Load dataset (only from the LG folder)\n",
    "images, labels, names = load_images_from_folder(dataset_path)\n",
    "print(f\"Read {len(images)} images from the LG folder with shape {images.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform data augmentation\n",
    "def create_data_augmentation_generator(images, labels):\n",
    "    # Create an ImageDataGenerator object for data augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=10,  # Rotation range of 10 degrees\n",
    "        width_shift_range=0.2,  # Width shift range of 20%\n",
    "        height_shift_range=0.2,  # Height shift range of 20%\n",
    "        zoom_range=0.15,  # Zoom range of 15%\n",
    "        fill_mode='nearest',  # Fill mode 'nearest' to avoid creating new pixels\n",
    "    )\n",
    "    \n",
    "    # Reshaping images to 4D array (num_samples, height, width, channels)\n",
    "    images_aug = images.reshape((images.shape[0], images.shape[1], images.shape[2], 1))\n",
    "    \n",
    "    # Return the generator that will perform the augmentation\n",
    "    return datagen.flow(images_aug, labels, batch_size=16)\n",
    "\n",
    "# Convert labels to categorical (one-hot encoding)\n",
    "labels = to_categorical(labels, num_classes=2)\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sneha Thakur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sneha Thakur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 649ms/step - accuracy: 0.7072 - loss: 67.2231 - val_accuracy: 0.7961 - val_loss: 0.5325\n",
      "Epoch 2/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 652ms/step - accuracy: 0.7816 - loss: 0.5402 - val_accuracy: 0.7961 - val_loss: 0.5151\n",
      "Epoch 3/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 646ms/step - accuracy: 0.7928 - loss: 0.5284 - val_accuracy: 0.7961 - val_loss: 0.5157\n",
      "Epoch 4/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 655ms/step - accuracy: 0.8013 - loss: 0.5081 - val_accuracy: 0.7943 - val_loss: 0.5173\n",
      "Epoch 5/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 649ms/step - accuracy: 0.8096 - loss: 0.4911 - val_accuracy: 0.7961 - val_loss: 0.5164\n",
      "Epoch 6/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 645ms/step - accuracy: 0.8112 - loss: 0.4947 - val_accuracy: 0.7961 - val_loss: 0.5157\n",
      "Epoch 7/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 651ms/step - accuracy: 0.7886 - loss: 0.5222 - val_accuracy: 0.7961 - val_loss: 0.5127\n",
      "Epoch 8/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 646ms/step - accuracy: 0.8013 - loss: 0.5022 - val_accuracy: 0.7961 - val_loss: 0.5084\n",
      "Epoch 9/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 655ms/step - accuracy: 0.7999 - loss: 0.5031 - val_accuracy: 0.7961 - val_loss: 0.5091\n",
      "Epoch 10/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 652ms/step - accuracy: 0.7868 - loss: 0.5217 - val_accuracy: 0.7961 - val_loss: 0.5098\n",
      "Epoch 11/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 655ms/step - accuracy: 0.8002 - loss: 0.5008 - val_accuracy: 0.7961 - val_loss: 0.5063\n",
      "Epoch 12/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 666ms/step - accuracy: 0.7767 - loss: 0.5348 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 13/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 673ms/step - accuracy: 0.7938 - loss: 0.5100 - val_accuracy: 0.7961 - val_loss: 0.5066\n",
      "Epoch 14/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 664ms/step - accuracy: 0.7964 - loss: 0.5050 - val_accuracy: 0.7961 - val_loss: 0.5085\n",
      "Epoch 15/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 662ms/step - accuracy: 0.7852 - loss: 0.5202 - val_accuracy: 0.7961 - val_loss: 0.5067\n",
      "Epoch 16/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 663ms/step - accuracy: 0.7963 - loss: 0.5069 - val_accuracy: 0.7961 - val_loss: 0.5102\n",
      "Epoch 17/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 664ms/step - accuracy: 0.7945 - loss: 0.5114 - val_accuracy: 0.7961 - val_loss: 0.5052\n",
      "Epoch 18/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 660ms/step - accuracy: 0.7869 - loss: 0.5229 - val_accuracy: 0.7961 - val_loss: 0.5071\n",
      "Epoch 19/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 657ms/step - accuracy: 0.7765 - loss: 0.5369 - val_accuracy: 0.7961 - val_loss: 0.5073\n",
      "Epoch 20/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 650ms/step - accuracy: 0.8036 - loss: 0.4969 - val_accuracy: 0.7961 - val_loss: 0.5098\n",
      "Epoch 21/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 646ms/step - accuracy: 0.7857 - loss: 0.5197 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 22/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 641ms/step - accuracy: 0.7887 - loss: 0.5165 - val_accuracy: 0.7961 - val_loss: 0.5066\n",
      "Epoch 23/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 654ms/step - accuracy: 0.7901 - loss: 0.5156 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 24/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.8019 - loss: 0.4999 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 25/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 647ms/step - accuracy: 0.7887 - loss: 0.5168 - val_accuracy: 0.7961 - val_loss: 0.5065\n",
      "Epoch 26/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 642ms/step - accuracy: 0.7865 - loss: 0.5199 - val_accuracy: 0.7961 - val_loss: 0.5072\n",
      "Epoch 27/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 641ms/step - accuracy: 0.7909 - loss: 0.5142 - val_accuracy: 0.7961 - val_loss: 0.5071\n",
      "Epoch 28/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 641ms/step - accuracy: 0.7894 - loss: 0.5160 - val_accuracy: 0.7961 - val_loss: 0.5057\n",
      "Epoch 29/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 635ms/step - accuracy: 0.8127 - loss: 0.4848 - val_accuracy: 0.7961 - val_loss: 0.5065\n",
      "Epoch 30/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 632ms/step - accuracy: 0.7913 - loss: 0.5140 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 31/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 637ms/step - accuracy: 0.7812 - loss: 0.5265 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 32/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 634ms/step - accuracy: 0.7919 - loss: 0.5123 - val_accuracy: 0.7961 - val_loss: 0.5062\n",
      "Epoch 33/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 634ms/step - accuracy: 0.8025 - loss: 0.4999 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 34/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 631ms/step - accuracy: 0.7999 - loss: 0.5003 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 35/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 633ms/step - accuracy: 0.7981 - loss: 0.5049 - val_accuracy: 0.7961 - val_loss: 0.5063\n",
      "Epoch 36/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 1s/step - accuracy: 0.8082 - loss: 0.4925 - val_accuracy: 0.7961 - val_loss: 0.5098\n",
      "Epoch 37/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 651ms/step - accuracy: 0.7916 - loss: 0.5155 - val_accuracy: 0.7961 - val_loss: 0.5065\n",
      "Epoch 38/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 645ms/step - accuracy: 0.7805 - loss: 0.5289 - val_accuracy: 0.7961 - val_loss: 0.5065\n",
      "Epoch 39/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 647ms/step - accuracy: 0.7950 - loss: 0.5093 - val_accuracy: 0.7961 - val_loss: 0.5066\n",
      "Epoch 40/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 635ms/step - accuracy: 0.8089 - loss: 0.4898 - val_accuracy: 0.7961 - val_loss: 0.5083\n",
      "Epoch 41/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 632ms/step - accuracy: 0.7998 - loss: 0.5041 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 42/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 634ms/step - accuracy: 0.7757 - loss: 0.5341 - val_accuracy: 0.7961 - val_loss: 0.5066\n",
      "Epoch 43/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 635ms/step - accuracy: 0.7975 - loss: 0.5055 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 44/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 641ms/step - accuracy: 0.7933 - loss: 0.5123 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 45/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 632ms/step - accuracy: 0.7987 - loss: 0.5042 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 46/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m767s\u001b[0m 5s/step - accuracy: 0.7935 - loss: 0.5094 - val_accuracy: 0.7961 - val_loss: 0.5073\n",
      "Epoch 47/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 649ms/step - accuracy: 0.7828 - loss: 0.5234 - val_accuracy: 0.7961 - val_loss: 0.5075\n",
      "Epoch 48/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 642ms/step - accuracy: 0.8036 - loss: 0.4946 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 49/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 641ms/step - accuracy: 0.7768 - loss: 0.5315 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 50/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 644ms/step - accuracy: 0.8056 - loss: 0.4971 - val_accuracy: 0.7961 - val_loss: 0.5107\n",
      "Epoch 51/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7933 - loss: 0.5106 - val_accuracy: 0.7961 - val_loss: 0.5062\n",
      "Epoch 52/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 638ms/step - accuracy: 0.7995 - loss: 0.5043 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 53/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.7862 - loss: 0.5221 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 54/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.8165 - loss: 0.4798 - val_accuracy: 0.7961 - val_loss: 0.5116\n",
      "Epoch 55/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7923 - loss: 0.5109 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 56/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.8140 - loss: 0.4854 - val_accuracy: 0.7961 - val_loss: 0.5106\n",
      "Epoch 57/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 638ms/step - accuracy: 0.7927 - loss: 0.5122 - val_accuracy: 0.7961 - val_loss: 0.5066\n",
      "Epoch 58/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 656ms/step - accuracy: 0.7964 - loss: 0.5070 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 59/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 644ms/step - accuracy: 0.8020 - loss: 0.4973 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 60/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 636ms/step - accuracy: 0.7945 - loss: 0.5091 - val_accuracy: 0.7961 - val_loss: 0.5075\n",
      "Epoch 61/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 641ms/step - accuracy: 0.8061 - loss: 0.4954 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 62/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 636ms/step - accuracy: 0.7955 - loss: 0.5063 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 63/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 674ms/step - accuracy: 0.7943 - loss: 0.5113 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 64/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 658ms/step - accuracy: 0.7809 - loss: 0.5276 - val_accuracy: 0.7961 - val_loss: 0.5108\n",
      "Epoch 65/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 636ms/step - accuracy: 0.8021 - loss: 0.4999 - val_accuracy: 0.7961 - val_loss: 0.5080\n",
      "Epoch 66/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 634ms/step - accuracy: 0.7891 - loss: 0.5164 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 67/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 638ms/step - accuracy: 0.7979 - loss: 0.5065 - val_accuracy: 0.7961 - val_loss: 0.5072\n",
      "Epoch 68/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 641ms/step - accuracy: 0.7862 - loss: 0.5221 - val_accuracy: 0.7961 - val_loss: 0.5075\n",
      "Epoch 69/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.7937 - loss: 0.5125 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 70/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 638ms/step - accuracy: 0.7779 - loss: 0.5307 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 71/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7971 - loss: 0.5058 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 72/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7936 - loss: 0.5124 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 73/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 641ms/step - accuracy: 0.7986 - loss: 0.5069 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 74/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 644ms/step - accuracy: 0.7991 - loss: 0.5042 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 75/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 641ms/step - accuracy: 0.8037 - loss: 0.4969 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 76/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7922 - loss: 0.5150 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 77/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 642ms/step - accuracy: 0.7777 - loss: 0.5336 - val_accuracy: 0.7961 - val_loss: 0.5077\n",
      "Epoch 78/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.7809 - loss: 0.5274 - val_accuracy: 0.7961 - val_loss: 0.5069\n",
      "Epoch 79/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 642ms/step - accuracy: 0.8078 - loss: 0.4919 - val_accuracy: 0.7961 - val_loss: 0.5078\n",
      "Epoch 80/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7975 - loss: 0.5065 - val_accuracy: 0.7961 - val_loss: 0.5068\n",
      "Epoch 81/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 642ms/step - accuracy: 0.7979 - loss: 0.5050 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 82/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 638ms/step - accuracy: 0.7955 - loss: 0.5084 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 83/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.8029 - loss: 0.5010 - val_accuracy: 0.7961 - val_loss: 0.5102\n",
      "Epoch 84/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 644ms/step - accuracy: 0.7879 - loss: 0.5203 - val_accuracy: 0.7961 - val_loss: 0.5066\n",
      "Epoch 85/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7870 - loss: 0.5194 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 86/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 644ms/step - accuracy: 0.7809 - loss: 0.5265 - val_accuracy: 0.7961 - val_loss: 0.5070\n",
      "Epoch 87/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7902 - loss: 0.5169 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 88/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7995 - loss: 0.5045 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 89/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 641ms/step - accuracy: 0.7938 - loss: 0.5114 - val_accuracy: 0.7961 - val_loss: 0.5069\n",
      "Epoch 90/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7958 - loss: 0.5082 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 91/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 640ms/step - accuracy: 0.7856 - loss: 0.5219 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 92/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 638ms/step - accuracy: 0.7980 - loss: 0.5015 - val_accuracy: 0.7961 - val_loss: 0.5063\n",
      "Epoch 93/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7980 - loss: 0.5054 - val_accuracy: 0.7961 - val_loss: 0.5064\n",
      "Epoch 94/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 641ms/step - accuracy: 0.7983 - loss: 0.5037 - val_accuracy: 0.7961 - val_loss: 0.5084\n",
      "Epoch 95/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 642ms/step - accuracy: 0.7775 - loss: 0.5319 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 96/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.7919 - loss: 0.5147 - val_accuracy: 0.7961 - val_loss: 0.5058\n",
      "Epoch 97/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 643ms/step - accuracy: 0.7937 - loss: 0.5100 - val_accuracy: 0.7961 - val_loss: 0.5060\n",
      "Epoch 98/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7920 - loss: 0.5132 - val_accuracy: 0.7961 - val_loss: 0.5061\n",
      "Epoch 99/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7976 - loss: 0.5071 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "Epoch 100/100\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 639ms/step - accuracy: 0.7892 - loss: 0.5170 - val_accuracy: 0.7961 - val_loss: 0.5059\n",
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - accuracy: 0.7836 - loss: 0.5224\n",
      "Test Accuracy: 79.61%\n"
     ]
    }
   ],
   "source": [
    "# Define the Small-VGG model\n",
    "def create_small_vgg():\n",
    "    model = Sequential()\n",
    "    # Block 1\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_size[0], image_size[1], 1)))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Block 2\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Block 3\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    # Dense layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(7200, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))  # Output layer for binary classification\n",
    "    return model\n",
    "\n",
    "# Compile and train the Small-VGG model\n",
    "model = create_small_vgg()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data augmentation generator\n",
    "train_generator = create_data_augmentation_generator(X_train, y_train)\n",
    "\n",
    "# Train the model using the augmented data\n",
    "history = model.fit(train_generator, epochs=100, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_acc * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       115\n",
      "           1       0.80      1.00      0.89       449\n",
      "\n",
      "    accuracy                           0.80       564\n",
      "   macro avg       0.40      0.50      0.44       564\n",
      "weighted avg       0.63      0.80      0.71       564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sneha Thakur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Sneha Thakur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Sneha Thakur\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test_classes, y_pred_classes))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
